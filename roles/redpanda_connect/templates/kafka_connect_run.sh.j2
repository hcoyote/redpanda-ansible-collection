#!/usr/bin/env bash
set -e
set +x

if [ -z "$CONNECT_HOME" ]; then
    export CONNECT_HOME="/opt/kafka"
fi

if [ -z "$CONNECT_PLUGIN_PATH" ]; then
    export CONNECT_PLUGIN_PATH="${CONNECT_HOME}/redpanda-plugins"
else
    export CONNECT_PLUGIN_PATH="${CONNECT_HOME}/redpanda-plugins,${CONNECT_PLUGIN_PATH}"
fi

# Get client rack if it's enabled from the file $CONNECT_HOME/init/rack.id (if it exists). This file is generated by the
# init-container used when rack awareness is enabled.
if [ -e "$CONNECT_HOME/init/rack.id" ]; then
  RACK_ID=$(cat "$CONNECT_HOME/init/rack.id")
  export RACK_ID
fi

# Create dirs where keystores and truststores will be stored
mkdir -p /tmp/kafka/additional

# Set certs password
if [ -z "$CONNECT_CERTS_STORE_PASSWORD_FILE" ]; then
  # Generate temporary keystore password
  CERTS_STORE_PASSWORD=$(< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c32)
else
  CERTS_STORE_PASSWORD=$(cat "/opt/kafka/connect-password/$CONNECT_CERTS_STORE_PASSWORD_FILE")
fi
export CERTS_STORE_PASSWORD

# Set certs password
if [ -z "$CONNECT_ADDITIONAL_CERTS_STORE_PASSWORD_FILE" ]; then
  # Generate temporary keystore password
  ADDITIONAL_CERTS_STORE_PASSWORD=$(< /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c32)
  echo "$ADDITIONAL_CERTS_STORE_PASSWORD" > /tmp/kafka/additional/additional-certs-store-password
else
  ADDITIONAL_CERTS_STORE_PASSWORD=$(cat "/opt/kafka/connect-password/$CONNECT_ADDITIONAL_CERTS_STORE_PASSWORD_FILE")
fi
export ADDITIONAL_CERTS_STORE_PASSWORD

# Import certificates into keystore and truststore
./kafka_connect_tls_prepare_certificates.sh
./kafka_connect_tls_prepare_additional_certificates.sh

if [ -z "$CONNECT_LOG_TOPIC" ]; then
    export CONNECT_LOG_TOPIC="__redpanda.connectors_logs"
fi

# Generate and print the config file
echo "Starting Kafka Connect with configuration:"
./kafka_connect_config_generator.sh | tee /tmp/redpanda-connectors.properties | sed -e 's/sasl.jaas.config=.*/sasl.jaas.config=[hidden]/g' -e 's/password=.*/password=[hidden]/g'
echo ""

# Disable Kafka's GC logging (which logs to a file)...
export GC_LOG_ENABLED="false"

# Generate custom log4j config
if [ -n "$CONNECT_LOG4J_CONFIGURATION" ]; then
    ./kafka_connect_log4j_config_generator.sh | tee /tmp/log4j-custom.properties
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:/tmp/log4j-custom.properties"
fi

LOG_LEVEL="WARN"
LOG_LEVEL_UPPER_CASE=$(echo "$CONNECT_LOG_LEVEL" | tr '[:lower:]' '[:upper:]')
if [ "$LOG_LEVEL_UPPER_CASE" == "DEBUG" ] || [ "$LOG_LEVEL_UPPER_CASE" == "INFO" ] || [ "$LOG_LEVEL_UPPER_CASE" == "ERROR" ]; then
  LOG_LEVEL=${LOG_LEVEL_UPPER_CASE}
fi

# enabling log4j logging to Redpanda topic
LOG4J_CONFIG_FILE="$CONNECT_HOME/config/log4j.xml"
REDPANDA_APPENDER_LOG4J_FILE="$CONNECT_HOME/config/log4j-redpanda.xml"
if [ -f "$REDPANDA_APPENDER_LOG4J_FILE" ] && [ "$(echo "$CONNECT_TOPIC_LOG_ENABLED" | tr '[:upper:]' '[:lower:]')" == "true" ]; then
  # if log4j-redpanda.xml file exists and CONNECT_TOPIC_LOG_ENABLED is explicitly set to 'true'
  LOG4J_CONFIG_FILE="$REDPANDA_APPENDER_LOG4J_FILE"
fi

if [ -z "$KAFKA_LOG4J_OPTS" ]; then
  echo "Using $LOG4J_CONFIG_FILE log4j config file"
  export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$LOG4J_CONFIG_FILE -Dlog4j_log_level=$LOG_LEVEL"
fi

# We don't need LOG_DIR because we write no log files, but setting it to a
# directory avoids trying to create it (and logging a permission denied error)
export LOG_DIR="$CONNECT_HOME"

# enabling Prometheus JMX exporter as Java agent
if [ "$(echo "$CONNECT_METRICS_ENABLED" | tr '[:upper:]' '[:lower:]')" != "false" ]; then
    KAFKA_OPTS="${KAFKA_OPTS} -javaagent:$CONNECT_HOME/redpanda-plugins/jmx-exporter/jmx_prometheus_javaagent.jar=9404:$CONNECT_HOME/config/jmx-exporter-config.json"
    export KAFKA_OPTS
fi

. ./set_kafka_jmx_options.sh "${CONNECT_JMX_ENABLED}" "${CONNECT_JMX_USERNAME}" "${CONNECT_JMX_PASSWORD}"

# This is to fix Snowflake connector instantiation of net.snowflake.ingest.internal.apache.arrow.memory.util.MemoryUtil
# class exception when using SNOWPIPE_STREAMING snowflake.ingestion.method.
# See https://arrow.apache.org/docs/java/install.html
export KAFKA_OPTS="${KAFKA_OPTS} --add-opens=java.base/java.nio=ALL-UNNAMED"

if [ -n "$JAVA_SYSTEM_PROPERTIES" ]; then
    export KAFKA_OPTS="${KAFKA_OPTS} ${JAVA_SYSTEM_PROPERTIES}"
fi

# Disable FIPS if needed
if [ "$FIPS_MODE" = "disabled" ]; then
    export KAFKA_OPTS="${KAFKA_OPTS} -Dcom.redhat.fips=false"
fi

# Configure heap based on the available resources if needed
. ./dynamic_resources.sh

# Configure Garbage Collection logging
. ./set_kafka_gc_options.sh

set -x

# starting Kafka server with final configuration
exec /opt/kafka/bin/connect-distributed.sh /tmp/redpanda-connectors.properties
